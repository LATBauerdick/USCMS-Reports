Detector Operations
===================

During the 3$^{rd}$ quarter the LHC and CMS have returned to physics
production running. The performance of the accelerator has been
excellent and the accumulation of luminosity has been ahead of schedule.
Towards the end of the quarter the accelerator had a planned technical
stop followed by a series of special runs and studies. During this
quarter, as reported below, significant progress has been made in
understanding the previously reported issue with DC/DC converters in the
pixel system.

![Luminosity, delivered by the LHC and recorded by CMS, through July
6.[]{label="fig:Lumi"}](int_lumi_per_day_cumulative.png){width="75%"}

BRIL 
-----

The Pixel Luminosity Telescope (PLT) together with the fast beam
condition monitor (BCM1F) and HF provide online luminosity measurements
continuously. The PLT was kept in cold storage, and reinstalled in the
last week of February. The fast readout for all telescopes works but two
telescopes exhibit degraded full pixel information that is used for
track-based studies. Reconstructed tracks are also used for fast
measurements of the beam spot and allow tracking of beam conditions.
Basic commissioning happened during the low luminosity period end of
April.

To overcome the degradation in charge collection in the silicon pixels
due continuous radiation damage, the electric field strength was raised.
To be able to reach higher strengths (max. HV on power supplies was
500V) new modules were installed and the operation voltage was set
safely above the turn over point. Below this point charge collection is
reduced. The point is monitored by repeated HV scans, and the procedure
has been automated. Recovery procedures for SEU are in place; in the
first iteration a reset of the readout loop, for severe SE upsets a full
power cycle.

PLT participated successfully in the VdM campaign end of June and the
visible cross section is obtained for the ongoing data taking. The
relative behavior of the visible cross section is monitored by analyzing
micro-VdM scans that occur at the beginning and at the end of a fill.
Changes are due to loss of efficiency. Measurements of efficiency and
accidentals are also obtained from analysis of tracks offline, and with
fast turnaround after completion of each fill.

With increasing irradiation, the operation will become more challenging;
it is expected that the turn-over point will reach the max. voltage for
safe operation before end of the run. From then on the efficiency will
need to be parameterized and applied as online correction.

The first planes for the refurbishment of the PLT during the LS are
arriving and readout cards are assembled. The laboratory is setup at P5
with 4 telescopes and with the plane test stand plane testing using a
radioactive source started.

  Working Metric                                Performance
  ------------------------------------------- -------------
  Fraction of telescopes fully operational              90%
  Efficiency of delivery of lumi histograms             99%
  Uptime of lumi histogram production               $>$ 99%
  Lumi lost                                           0 /pb

  : BRIL Metrics

[\[BRILMetrics\]]{#BRILMetrics label="BRILMetrics"}

  Subsystem   Description                                Scheduled   Achieved
  ----------- ---------------------------------------- ----------- ----------
  BRIL        Pixel Luminosity Telescope reinstalled         March      March
  BRIL        Update Lumi for 2017                           March      March
  BRIL        Ready for Beams                                April      March
  BRIL        Preliminary Luminosity for Conferences          July 
  BRIL        Improve 2018 Lumi numbers                   December 

  : BRIL Milestones

[\[BRILMIlestones\]]{#BRILMIlestones label="BRILMIlestones"}

Tracker 
--------

The start up this year was very smooth and we were able to take physics
data fairly quickly. The DCDC replacement in the phase 1 pixels was a
success, and the nature of the DCDC failures was determined well enough
to avoid DCDC losses so far in 2018. Alignment and physics performance
is good and we are hoping operations will continue to be as uneventful
as they are currently. Recently, a tracker monitoring group has been
formed to share strips and pixels resources in monitoring online
detector conditions, such as temperatures and error conditions and
operations on a DCDC test setup on the Castor table. The idea is to make
it easier to access and analyze conditions information as well as
monitor long term trends. We are also revisiting the criteria for
requesting urgent accesses to replace things like a malfunctioning power
supply. The current High Level Trigger/reconstruction has more
mitigation possible now than in 2017, some due to real-time conditions
information we include in the data stream from the detector and some due
to taking advantage of the detector redundancy. In the 2018 detector, it
is not as crucial to have all the tracker taking data all the time.

### Pixels 

We have had to power off part (2.7%) of the BPiX due to what looks like
a connection issue in the power system on the detector. The impact on
physics is very small since the areas effected are non-overlapping.
Additionally, 2 (of 96) layer 1 modules were lost when we attempted to
raise the high voltage (HV) as a radiation damage mitigation. Further
attempts to raise the HV are stopped while we investigate in the lab.
During the layer 1 HV investigations, we improved the procedure for
power supply replacement and used some previously untapped capability in
the voltage distribution system to limit the impact of a shorting
module.

Substantial progress has been made in understanding the causes of DCDC
converter losses in 2017. We have adopted the findings into our detector
operations. In order to stop the DCDCs from breaking, we run the DCDC
with 9V (lower) input voltage and we toggle the power for stuck modules
using the low voltage power supplies (LVPS) rather than the
enable/disable feature of the DCDC. After about 7 kGy, it was found that
the DCDC becomes vulnerable to damage from an uncompensated leakage
current causing an overvoltage inside the DCDC chip when the DCDC is
disabled. We have also added an automatic ramping of the HV when we
toggle the LVPS to prevent the ROCs from being damaged. The tally of
unrecoverable/noisy/low efficiency ROCs from damage due to HV on and LV
off in 2017 is about 0.3% of the FPiX, with most of the damage occurring
in areas overlapped by working adjacent modules.

The deployment of a much faster firmware for the downloading of
constansts to the modules has shortened the module configure time by as
much as a factor of 30. The fast firmware also substantially shortens
the time we spend recovering from Single Event Upsets (SEU's) and allows
us to fully download all the constants to each module for each SEU
recovery. This is a substantial advantage for maintaining detector
efficiency for some types of SEU's which formerly resulted in a dynamic
masking of 1-2% of the FPiX/SEU.

### Strips

We have masked about 0.5% of the strips due to control rings which
become non-responsive during collisions. These rings are operating in a
redundant mode and it appears and SEU can sometimes force the control
ring into a difficult to recover state. Rather than carve out the time
needed to reconfigure the ring during collisions, we have decided to
mask the channels until a less invasive recovery procedure can be
developed.

                                         Pixels   Strips
  ------------------------------------- -------- --------
  \% Working channels                     95.1     95.7
  Downtime attributed in pb$^{-1}$        67.4    116.7
  Fraction of downtime attributed (%)     12.1     21.0

  : Tracker Metrics

[\[TrackerMetrics\]]{#TrackerMetrics label="TrackerMetrics"}

  Subsystem   Description                              Scheduled   Achieved
  ----------- -------------------------------------- ----------- ----------
  Tracker     Pixel Phase 1 Detector Removed              Jan 20     Jan 20
  Tracker     New pixel DC-DC converters installed        Jan 30     Jan 30
  Tracker     Pixel Phase 1 Detector Re-installed         Feb 21     Feb 21
  Tracker     Strips and Pixel Phase 1 Detector                  
              Ready for Collisions                        May 11     Apr 19

  : Tracker Milestones

[\[TrackerMilestones\]]{#TrackerMilestones label="TrackerMilestones"}

ECAL 
-----

In the run up to physics operations, all of the now standard procedures
for bringing the ECAL into operation were performed with US personnel
involved in many different areas. Some new features were the
optimization of new Data Concentrator Card (DCC) firmware which exploits
the larger s-link buffer and fixes a problem with CRC errors in the data
transmission. Also the auto-masking of hot trigger towers which is
managed by a software package called COKE was retuned.

During the commissioning of the L1 trigger and unusually high prefiring
rate was observed increasing in eta. This is now understood to be due to
the effects of radiation damage changing the pulse shape casuing timing
drifts. It is mitigated by adjusting the timing delays. The inotial
energy intercalibrations were those from the 2017 run. These provided a
very stable $Z \rightarrow ee$ mass peak in the initial running. The
full 2018 calibration is rather involved and takes several months to
complete.

After commisssioning the running has been very stable with just minor
DAQ issues causing some downtime and two incidents of problems with the
MARATON low voltage power supplies.

  Metric                                   Performance
  -------------------------------------- -------------
  Fraction of channels operational: EB            99 %
  Fraction of channels operational: EE          98.3 %
  Fraction of channels operational: ES          99.9 %
  Downtime attributed pb$^{-1}$                     19
  Fraction of downtime attributed               2.59 %
  Resolution performance                            2%

  : ECAL Metrics

[\[ECALMetrics\]]{#ECALMetrics label="ECALMetrics"}

  Subsystem   Description                                            Scheduled   Achieved
  ----------- ---------------------------------------------------- ----------- ----------
  ECAL        ECAL fiully powered on with HV/LV fully functional       March 1    March 1
  ECAL        Complete sLINK upgrade and tests                        March 21    April 1
  ECAL        Initial thresholds and calibrations set                  April 1    April 1
  ECAL        Ready for Beam                                          April 15    April 1
  ECAL        Preliminary Calibration                                  June 15 

  : ECAL Milestones

[\[ECALMilestones\]]{#ECALMilestones label="ECALMilestones"}

HCAL
----

During the second quarter of 2018, the HCAL Operations group focused on
smoothly taking data, specifically including with the upgraded HE.

The decision to proceed with the full HE Phase 1 Upgrade was taken in
January 2018. (The upgrade has silicon photomultipliers (SiPMs) instead
of HPDs and has the new version of the QIE frontend chip, the QIE11. In
addition, the longitudinal segmentation of the HE is increased to allow
for radiation damage compensation.)

The HE upgrade was successfully installed in the first quarter of 2018.
The installation proceeded smoothly due to the excellent performance of
the HE upgrade team, and to the careful planning and numerous tests that
were done prior to the installation.

Aside from the increased longitudinal segmentation, the upgraded HE has
been shown to have a more uniform response by a factor of 3, drastically
improved signal-to-noise with MIP signals now above noise. In addition
the the effects of radiation damage increase due to increased integrated
luminosity will be smaller.

The HCAL was ready for the start of data taking in spring 2018, and has
been running smoothly with a few rare issues. Data losses during offline
certification due HCAL problems were 223 pb$^{-1}$ out of the first
21.5 fb$^{-1}$ collected or 1.0% . Data recording inefficiency due to
HCAL data acquisition issues was 70 pb$^{-1}$ or about 13% of all CMS
data collection downtime.

Work on HCAL calibration continues and and calibration accuracy is
already at the few percent level.

The concerns about the DCDC converters in HCAL have now been shown not
be an issue. Problems with the DCDC converters have been shown to start
above 7 kGy of radiation. The pixel detector where problems were
observed in 2017 received about 10 kGy that year. However, the DCDC
converters in the HCAL are expected to receive several orders of
magnitude less radiation even in high Luminosity LHC running and so the
DCDC converters should not be a problem for HCAL.

\
February 28 Milestone\
HE Phase 1 Installed and Co-60 Calibration completed. This milestone was
achieved Feb. 24.

April 1 Milestone\
HE Detector Commissioned. This milestone was achieved March 15.

June 1 milestone\
Data losses due to HCAL less than 1%. This milestone was achieved at the
end of June.

\vspace*{5mm}
  Metric                                    Performance
  --------------------------------------- -------------
  Fraction of channels operational: HF            100% 
  Fraction of channels operational: HE          99.92% 
  Fraction of channels operational: HB           99.88%
  Fraction of channels operational: HO           99.72%
  Downtime attributed to HCAL pb$^{-1}$              70
  Fraction of CMS downtime due to HCAL             13% 
  Abs Energy Calibration                           2-3%
  Inter-calibration Uniformity                       2%

  : HCAL Metrics

[\[HCALMetrics\]]{#HCALMetrics label="HCALMetrics"}

  Subsystem   Description                                            Scheduled   Achieved
  ----------- ---------------------------------------------------- ----------- ----------
  HCAL        HE Phase 1 Installed & Co-60 calibration completed        Feb 28     Feb 24
  HCAL        HE Detector Commissioned                                   Apr 1   March 15
  HCAL        Ready for Physics                                         Apr 15    April 1
  HCAL        Data Loss $<  1\%\$                                       June 1    June 30
  HCAL        1% to 2% Calibration                                      July 1 

  : HCAL Milestones

[\[HCALMilestones\]]{#HCALMilestones label="HCALMilestones"}

EMU 
----

### Operations at CERN

The CSC system was ready for the first collision data of 2018 and
generally ran smoothly and efficiently in this quarter. Some isolated
incidents caused a small amount of downtime (2% of the CMS total
downtime of 6%) or lost data. These included a case where one endcap
went out of synchronization and another where a LV power supply shut
down spontaneously.

New firmware was installed in the ODMB card to detect and disable
channels where the optical link data is corrupt. This has allowed the
CSC to continue running until an appropriate opportunity arises to
recover the bad link.

Occasional interrupt errors are seen in the CSC FED system every since
the upgrade of the online operating system and libraries (to CENTOS7 and
XDAQ14) during the year end technical stops. Investigation continues.
Only once did these errors cause any downtime.

We have continued to see some of the Finisar optical transceivers in the
DCFEBs fail in a way that cannot be recovered with resets and power
cycles. A total of 19 of these transceivers have failed since 2016, out
of a total of 1008 in use on the detector. We are exploring the
possibility of replacing all of these transmitters during LS2. A design
has been made at OSU for an adapter board that would allow a CERN VTTx
transmitter to be put in place of the Finisar transceivers.

There was longstanding problem where a time marker (BC0) was not being
reported from some chambers to the EMTF triggers system. This was
understood and corrected during the June Technical Stop.

At the end of June, 98.7% of the channels in the CSC system were working
and being read out. This is down slightly from 99.0% at the beginning of
the quarter. There are two chambers off due to low voltage issues,
inherited from 2017, and these will not be accessible for repair until
Long Shutdown 2.

Just before the start of the collider run, additional shielding was
installed in the forward beam region to try to reduce the observed
excess of segments in top of ME4/2 ring. The excess was not expected to
be eliminated and the quantitative effect has being assessed and found
to be very marginal (\<10% improvement).

The CSC spatial resolution was measured in all CSC types from 2018 data.
The resolutions were consistent with those measured in the 2017 data and
earlier. For the first time, the resolution was measured as a function
of instantaneous luminosity; a gradual degradation, between 1% and 5%
depending on the chamber type, of the spatial resolution was seen with
luminosity increasing from $0.6\times 10^{34}$ to $2.0\times 10^{34}$
Hz/cm$^2$.

In the GIF++ facility, an ME1/1 chamber is being irradiated with a
reduced fraction of CF$_4$ (2% instead of 10%) and performance studies
with a muon test beam were carried out there in in late April.

  \% Working channels                  98.7%
  --------------------------------- ------------
  Downtime attributed pb$^{-1}$         8.0
  Fraction of downtime attributed        2%
  Median spatial resolution          127 $\mu$m

  : CSC Metrics

[\[CSCMetrics\]]{#CSCMetrics label="CSCMetrics"}

  ------------------------------------------------------
  Subsystem   Description         Scheduled Achieved
  ----------- ----------------- ----------- ------------
  EMU                               April 4 March 29

  EMU         New HV settings       July 31 
              for reduced gain              
  ------------------------------------------------------

  : EMU Milestones

[\[EMUMilestones\]]{#EMUMilestones label="EMUMilestones"}

### MEX/1 Detector Improvement

In April, a workshop was held at Texas A&M University to discuss the
work on electronics in the CSC and GEM systems. About 40 physicists and
engineers attended. The scope of the discussions included the MEX/1
detector improvement projects, and allowed some final technical choices
to me made, including the power management of the GBTx chips, the
optical fiber configuration, and the elimination of legacy copper
connections that are being replaced with optical connections.

The ALCT mezzanine prototypes of both types (LX100 and LX150T) were
received at UCLA and tested. The bench tests were successful, and the
ALCT had USCMS Production Readiness Review on June 8th. The review was
positive, with one requirement to carry out successful integration tests
with the prototypes at CERN before proceeding to production. These tests
are currently underway.

After some delays in getting the funding in place, the second prototypes
for the DCFEBv2 were fabricated and assembled. A small modification was
needed to the boards to eliminate clock reflections, but after this
change the boards passed all bench tests at the Ohio State University.
One of the boards was sent to CERN for integration tests and another to
Rice for additional bench tests and online software development. The
quotes for the full production of DCFEBv2 boards were requested in mid
June after the funding was in place. There is still concern about
components with long lead times.

The low voltage power requirements were calculated in detail for
currents and voltages expected with the new electronics. These
calculations confirmed that twelve new Maraton supplies will be needed,
and this order was placed at the end of June.

The low voltage distribution boards (LVDB), which are a Russian
responsibility, progressed according to schedule with the production
fabrication completed and all components procured.

A well-attended workshop was held at CERN (and by video conference) on 7
June for planing and team formation for the CSC work in LS2 for the
installation and testing of the new electronics.

The CMS Electronics System Review for the LS2 CSC on-chamber electronics
improvement is scheduled for 2 July. The main focus of this review is
the ALCT mezzanine boards and the DCFEBv2 boards, but it also covers the
LVDB5, HV and LV infrastructure, and optical fiber additions. The USCMS
Production Readiness Review for the DCFEBv2 board is being held in
conjunction with the ESR.

\def1.5{1.5}
  -------------------------------------------------------------
  Subsystem   Description                Scheduled Achieved
  ----------- ------------------------ ----------- ------------
  EMU-MEX/1   ALCT mezzanine prototype      Apr 30 Apr 6
              received                             

  EMU-MEX/1   Second xDCFEB prototype        May 1 Jun 1
              received                             

  EMU-MEX/1   CSC On-chamber                Jun 15 Jul 2
              Electronics System                   
              Review completed                     

  EMU-MEX/1   Order placed for Maraton      Aug 31 Jun 25
              LV supplies                          

  EMU-MEX/1   Production of xDCFEB           Sep 2 
              PCBs released                        

  EMU-MEX/1   CSC on-chamber optical         Nov 1 
              fibers ready for                     
              installation                         

  EMU-MEX/1   CSC LV junction boxes         Jan 15 
              ready for installation        (2019) 
  -------------------------------------------------------------

  : EMU Milestones - MEX/1 Detector Improvement

[\[EMUMilestones-MEX1\]]{#EMUMilestones-MEX1 label="EMUMilestones-MEX1"}

DAQ
---

The data taking was mostly smooth during the reporting period. LHC fills
typically started at a L1 trigger rate of 80 kHz. The event size before
HLT compression is about 1.4 MB. The HLT output does not exceed 4 GB/s,
which includes additional data providing an unbiased sample of B decays.
These triggers are gradually enabled when the luminosity drops during
the fill. From measurements carried out in DAQ emulator mode at the
beginning of the reporting period, we estimate that we can record up to
5 GB/s and simultaneously transfer this rate to Tier 0 when the Lustre
storage occupancy is below 50%. The available throughput to Tier 0
became more predictable since EOS has been reconfigured at the beginning
of June to place the second replica instead of Wigner also in Meyrin. We
implemented a "stop button" which enables the shift crew to switch off
the B-physics streams in case of problems transferring to or processing
the data at Tier 0. This action would be taken when the Lustre occupancy
reaches 45% to avoid any repercussions on the core physics program.
However, the Lustre occupancy has not exceeded 35% so far.

The only major problem concerns the file distribution from the builder
units to the filter units. Since the data taking resumed this year, the
locking of files over NFS is no longer reliable. This results in an
occasional (few in a week) loss of a LS and requires manual intervention
to close the affected run. This is likely related to the upgrade of
CentOS/NFS versions on the filter units early 2018. This upgrade was
needed to support the new Skylake HLT nodes installed earlier this year.
We are working on a new solution for the file distribution which does
not rely on any file locking.

The throughput from a builder unit to the new Skylake HLT nodes has been
confirmed to be about 3 GB/s. We found no measurable difference from the
CC7.4 upgrade nor Meltdown/Spectre mitigations deployed on the filter
units. We also measured the available CPU capacity on the HLT. For this
we removed filter units from an ongoing physics run until the DAQ/HLT
asserted backpressure. Assuming a linear scaling of the CPU load with
luminosity, the HLT farm would be saturated at a L1 trigger rate of
100 kHz and a luminosity of $2\times10^{34}cm^{-2}s^{-1}$. A detailed
analysis is ongoing by TSG to calibrate the offline HLT timing
measurements to the online findings.

In preparation of the heavy-ion run planned for November, we measured
the event-builder performance for the estimated heavy-ion fragment-size
distribution. The main difference with respect to previous Pb-Pb running
is the data reduction in the outer tracker (strips) back-end
electronics. The achievable L1 trigger rate for the expected event size
of 3.2 MB is about 50 kHz. This is well above the target rate of 30 kHz.
Therefore, no changes are necessary to the standard event-builder
configuration.

A second version of the online monitoring system (OMS) has been
released. The new version provides besides many bug fixes and additional
features, new L1 trigger pages with historical and live rates and plots.
The user can select which quantities are displayed. A review of the OMS
took place during the CMS week in June. The user-interface development
is on a good track, and the most important pages should become available
during the remainder of the year. However, the development of the
backend has stalled due to manpower issues. It is unlikely that a new
backend system can be tested before the LHC stops operating for 2 years
in Long Shutdown 2 (LS2).

The HLT online cloud was ramped up during the reporting period. It is
now using 87% of the HLT nodes (63k virtual cores) during interfill and
technical stops. It contributes a significant amount of CPU time for
offline processing. During the recent technical stop, the online cloud
processed more jobs in a week than the Fermilab Tier-1 site.

The DAQ group developed a plan for the LHC long shutdown 2 in 2019/20.
During this period, most computer and network equipment has to be
replaced as it reaches the end of its useful life. The downtimes of the
central services and of the DAQ system during the switch-over from the
current DAQ to the new run-3 DAQ system require a careful scheduling in
order to minimize the impact on the work carried out by the subsystem
during this time.

The first step in commissioning the testbed for the run-3 DAQ system has
been taken. 16 Skylake-based computers have been connected to 100 Gbps
Infiniband (EDR). Initial measurements using the event-builder software
look promising. The commissioning of the Ethernet network will be done
during July.

  Dead time due to backpressure      0.7%
  --------------------------------- ------
  Downtime attributed pb$^{-1}$      6.5
  Fraction of downtime attributed    1.3%

  : DAQ Metrics

[\[DAQMetrics\]]{#DAQMetrics label="DAQMetrics"}

  ---------------------------------------------------------------
  Subsystem   Description                    Scheduled   Achieved
  ----------- ---------------------------- ----------- ----------
  DAQ         First version of OMS GUI           Mar 1      Mar 6
              with limited functionality               
              deployed                                 

  DAQ         Specification and design           Apr 1     Mar 13
              outline for DTH prototype P1             

  DAQ         New HLT nodes commissioned         May 1      Apr 5

  DAQ         Testbed for DAQ 3 installed        Jun 1 

  DAQ         First DTH prototype P1 board       Oct 1 

  DAQ         Event-builder and SMTS ready      Oct 31 
              for heavy-ion run                        

  DAQ         All relevant WbM pages            Dec 31 
              migrated to new OMS GUI                  
  ---------------------------------------------------------------

  : DAQ Milestones

[\[DAQMilestones\]]{#DAQMilestones label="DAQMilestones"}

\clearpage
Trigger
-------

During this quarter the US groups continued their work on the Layer-1
calorimeter (CaloL1) trigger and the endcap muon trigger systems
providing improvements and reliable running during 2018 data taking
operations.

### Endcap Muon Trigger

The Northeastern, Rice University, and University of Florida groups have
continued to make improvements to the EMTF, and have provided
operational support that led to smooth data-taking operations during the
2018 proton collider run so far. The firmware on the MPCs and the EMTF
were updated, and this allowed to unmask 6 CSC optical links that
previously were masked during 2017 because of errors. The ability to
mask RPC links was also added, in case problems are encountered.
Additionally, the EMTF firmware implemented several options to recover a
CSC link that has lost or otherwise has a mistimed BC0 orbit timing
marker. A rare bug that caused the PT LUT to be corrupted during the
resynchronization of optical links was also fixed.

The online SWATCH software for EMTF was modified to monitor every link
for a lost BC0 timing marker, and to launch a procedure to attempt to
recover it if so (in conjunction with firmware). Additionally, the
functionality to accommodate new registers to mask RPC links and to
configure new algorithm settings in the EMTF was added to the software.

Progress on the new "Auto-DQM" used to make spotting problems in DQM
plots easier continues, and has helped identify a few problems for the
CSC group to follow up. Additionally, data recorded by the EMTF was used
recently for a study to project the DAQ needs of the CSC system during
HL LHC. One spin-off from that study is that the LCT occupancy in each
chamber type has been measured, and can be used to project the input LCT
rate for an HL LHC endcap muon trigger.

### Layer-1 Calorimeter Trigger

The Layer-1 Calorimeter Trigger (CaloL1), built by the University of
Wisconsin - Madison, is a part of the completed Calorimeter Phase-1
Trigger Upgrade. CaloL1 has been operated smoothly since being powered
on after the Year-End Technical Stop (YETS) on January 25, 2018. The
University of Wisconsin - Madison group is responsible for the
maintenance and operation of the CaloL1.

During first quarter 2018 a discussion with HCAL led to decision to use
linear scale for trigger primitives compression, it required updating
the LUTs in CaloL1 and producing a new calibration. The LUTs were
updated, the calibration was done in April and May 2018 and was used in
CaloL2 calibration. Both systems updated their calibration constants.

The CaloL1 successfully operated with first beam tests in April and
provides now a smooth data taking in collisions and cosmic running for
tests. No dead time is due to CaloL1, in the data from approximately 22
fb-1 of luminosity is collected thus far.

The MIcroSD cards on two CTP7's were replaced since they failed during
the first operations period after extensive diagnostics were undertaken
before data-taking requiring many cycles of writing information on the
cards to investigate local network problems which were solved. The card
replacement did not cause any delay in data taking, since they were
swapped during the time when the LHC was preparing for the beam
operation. No other microSD cards have failed since then and changes to
the software and firmware have been made to prevent writing to the
MicroSD cards until all are replaced with more robust cards. All spare
CTP7s not in operation at P5 have had their MicroSD cards replaced.

A CaloL1 study of pre-firing of the ECAL endcap Trigger Primitives
identified a small problem with higher eta ECAL endcap deposits
incorrectly associated with the previous bunch crossing that was fixed
and a method of addressing this in data where it occurred was provided
by the ECAL group.

  Frac of MPC Channels                                100%
  -------------------------------------------------- ------
  Frac of Upgrade EMUTF Channels                      100%
  Deadtime attributed to EMTF pb$^{-1}$               8.4
  Fraction of deadtime attributed to EMTF             0.9%
  Frac of Calo. Layer-1 Channels                      100%
  Deadtime attributed to Calo. Layer-1 pb$^{-1}$       0
  Fraction of deadtime attributed to Calo. Layer-1     0%

  : Trigger Metrics

[\[TriggerMetrics\]]{#TriggerMetrics label="TriggerMetrics"}

  Subsystem   Description                         Scheduled   Achieved
  ----------- --------------------------------- ----------- ----------
  TRIG        EMTF commissioned with                        
              endcap RPC input                      April 1   April 27
  TRIG        EMTF ready for Physics                  May 1     May 29
  TRIG        Calo. Layer-1 commissioned                    
              with new ECAL/HCAL/HF Calib           April 1     May 19
  TRIG        Calo. Layer-1 Ready for physics       April 1     May 19

  : Trigger Milestones

[\[TriggerMilestones\]]{#TriggerMilestones label="TriggerMilestones"}
