<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}.c1{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:234pt;border-top-color:#000000;border-bottom-style:solid}.c2{color:#000000;font-weight:normal;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c5{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c15{padding-top:0pt;padding-bottom:0pt;line-height:1.38}.c8{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c14{border-collapse:collapse;margin-right:auto}.c0{orphans:2;widows:2;direction:ltr}.c16{padding-top:0pt;padding-bottom:0pt}.c4{color:#1155cc;text-decoration:underline}.c9{font-size:16pt;font-family:"Trebuchet MS"}.c6{color:inherit;text-decoration:inherit}.c10{padding-top:10pt;padding-bottom:0pt}.c7{height:0pt}.c3{height:11pt}.c12{line-height:1.15}.c18{line-height:1.7999999999999998}.c13{color:#666666}.c11{page-break-after:avoid}.c17{font-style:italic}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c8"><h1 class="c0 c10 c11"><a id="h.l42ufzbj6n4e" name="h.l42ufzbj6n4e"></a><span class="c9">Summary of Software and Computing activities</span></h1><p class="c0 c3"><span></span></p><p class="c0"><span>As the LHC has settled into stable operations in the last quarter of FY15, the U.S. CMS Software and Computing Operations Program has also entered a very operational mode. &nbsp;Various aspects of operations, both of the central processing and data management systems, have become routine, with adjustments as necessary as experience is gained. &nbsp;This has been facilitated by the various development efforts carried out during the shutdown. &nbsp;While development continues on many products and services, the top priority is supporting current operations, with an eye towards the use of new resources such as the Amazon cloud or clusters at supercomputing centers. &nbsp;CMS software has seen the benefits of the multi-threaded framework, and development has continued to expand the scope of those gains. &nbsp;As a result of all of this, facilities at both Fermilab and the universities have seen increasing amounts of activity, both centrally- and user-controlled. &nbsp;The facilities have been much more full than in recent previous quarters, but site performance has remained just as good. &nbsp;End-of-year hardware purchases, both completed and planned, will help to keep up with the demand. &nbsp;</span></p><h1 class="c0 c10 c11"><a id="h.ufkwr5smmn6f" name="h.ufkwr5smmn6f"></a><span class="c9">Major milestones achieved this quarter</span></h1><a href="#" id="43d67941029bde7f8e6aa0cb9b3c0a0281403ecc" name="43d67941029bde7f8e6aa0cb9b3c0a0281403ecc"></a><a href="#" id="0" name="0"></a><table cellpadding="0" cellspacing="0" class="c14"><tbody><tr class="c7"><td class="c1" colspan="1" rowspan="1"><p class="c5 c0"><span class="c2">Date</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c0 c5"><span class="c2">Milestone</span></p></td></tr><tr class="c7"><td class="c1" colspan="1" rowspan="1"><p class="c5 c0"><span class="c2">July 2015</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5 c0"><span class="c2">Production release CMSSW_7_5_0 made available</span></p></td></tr><tr class="c7"><td class="c1" colspan="1" rowspan="1"><p class="c5 c0"><span class="c2">August 2015</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5 c0"><span class="c2">Implement continuous integration for WMAgent</span></p></td></tr><tr class="c7"><td class="c1" colspan="1" rowspan="1"><p class="c5 c0"><span class="c2">September 2015</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c5 c0"><span class="c2">FY15 Tier 1 purchases completed</span></p></td></tr></tbody></table><h1 class="c0 c10 c11"><a id="h.aaxouebw8q0q" name="h.aaxouebw8q0q"></a><span class="c9">Fermilab Facilities</span></h1><p class="c0 c3"><span></span></p><p class="c0"><span>LHC Run 2 continued through the 4th quarter of the 2015 fiscal year, with the FNAL facility accepting over a petabyte of LHC collision data so far. &nbsp;As the run continues in earnest, utilization of the Tier 1 has also increased from shutdown levels, with the FNAL facility being full to capacity becoming the norm rather than the exception. &nbsp;Site readiness improved over the previous quarter, with FNAL passing CMS site tests 98% of the time for the quarter as shown in Figure 1.</span></p><p class="c0 c3"><span></span></p><p class="c0 c3"><span></span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 173.13px;"><img alt="" src="images/image02.png" style="width: 624.00px; height: 173.13px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0 c3"><span></span></p><p class="c0 c3"><span></span></p><p class="c0"><span>The FY15 hardware purchase cycle was completed this quarter, with hardware beginning to arrive and be installed late September. &nbsp;We were able to take advantage of very good market pricing this year both for disk and CPU, and used this to buy ahead for the next two years, when significant budget pressure is expected from the Phase 2 upgrade program. &nbsp;FNAL purchased 168 nodes of 48 core Intel CPU based batch nodes, and approximately 8 PB of disk storage toward the 2016, and to some extent 2017, CMS pledges. The increase in size of the batch farm requires upgrades in network connectivity to the storage pools, and management reserve funds were used to facilitate this. &nbsp;Almost 6 PB of tape media was also purchased and installed to hold incoming Run 2 data.</span></p><p class="c0 c3"><span></span></p><p class="c0 c3"><span></span></p><h1 class="c0 c10 c11"><a id="h.tr3etid1a63q" name="h.tr3etid1a63q"></a><span class="c9">University Facilities</span></h1><p class="c0 c3"><span></span></p><p class="c0"><span>The fourth quarter of FY15 saw a continuing increase in the usage of the U.S. CMS Tier-2 facilities as LHC Run II continued, as seen in Figure 2. This increase was largely due to running the CMS data reconstruction at the U.S. Tier-2 sites. &nbsp;This workflow has been possible at Tier-2 sites since May, thanks in part to development work undertaken during the shutdown. &nbsp;These workflows place a heavy strain on the internal networking capabilities of the sites, but our sites are all able to handle the increased load. Physics analysis with CRAB3 is also increasing.</span></p><p class="c0 c3"><span></span></p><p class="c0"><span>The seven U.S. sites are planning or are in the process of finalizing their hardware purchases for 2015. The connection of the Tier-2 sites to the LHCONE VPN by ESNet is proceeding in an orderly manner and should be completed this quarter. All sites have deployed the HTCondor-CE computing element, and have either retired or are planning to retire their GRAM CEs very soon.</span></p><p class="c0 c3"><span></span></p><p class="c0"><span>All of the U.S. CMS Tier-2 sites have operated successfully this quarter. On our two official performance metrics based on CMS test jobs, all sites were at least 92.4% &ldquo;</span><span class="c4"><a class="c6" href="https://www.google.com/url?q=http://wlcg-sam-cms.cern.ch/templates/ember/%23/historicalsmry/heatMap?end_time%3D2015%252F10%252F01%252000%253A00%26granularity%3DDaily%26hosts%3D%26profile%3DCMS_CRITICAL_FULL%26site%3DT2_US_Caltech%252CT2_US_Florida%252CT2_US_MIT%252CT2_US_Nebraska%252CT2_US_Purdue%252CT2_US_UCSD%252CT2_US_Wisconsin%26start_time%3D2015%252F07%252F01%252000%253A00%26type%3DAvailability%2520Ranking%2520Plot&amp;sa=D&amp;ust=1452568253785000&amp;usg=AFQjCNHAxB-bcK48v1dwMfSbDju6Jpq0QQ">available</a></span><span>&rdquo; (a 4.4% improvement over the third quarter 2015) and 95% &ldquo;</span><span class="c4"><a class="c6" href="https://www.google.com/url?q=http://dashb-ssb.cern.ch/dashboard/request.py/sitereadinessrank?columnid%3D45%26view%3DSite%2520Readiness%23time%3Dcustom%26start_date%3D2015-07-01%26end_date%3D2015-10-01%26values%3Dfalse%26spline%3Dfalse%26debug%3Dfalse%26resample%3Dfalse%26sites%3Dmultiple%26clouds%3Dall%26site%3DT2_US_Caltech,T2_US_Florida,T2_US_MIT,T2_US_Nebraska,T2_US_Purdue,T2_US_UCSD,T2_US_Wisconsin&amp;sa=D&amp;ust=1452568253786000&amp;usg=AFQjCNGiiUyLYxSRBFJPk7cbRrO8PPhNqg">ready</a></span><span>&rdquo;, 1% better than last quarter. The CMS goal for each of these metrics is 80%. The U.S. CMS Tier-2 centers delivered </span><span class="c4"><a class="c6" href="https://www.google.com/url?q=http://dashb-cms-jobsmry.cern.ch/dashboard/request.py/consumptions_individual?sites%3DT2_AT_Vienna%26sites%3DT2_BE_IIHE%26sites%3DT2_BE_UCL%26sites%3DT2_BR_SPRACE%26sites%3DT2_BR_UERJ%26sites%3DT2_CH_CSCS%26sites%3DT2_CN_Beijing%26sites%3DT2_DE_DESY%26sites%3DT2_DE_DESY_Test%26sites%3DT2_DE_RWTH%26sites%3DT2_EE_Estonia%26sites%3DT2_EE_Estonia_Test%26sites%3DT2_ES_CIEMAT%26sites%3DT2_ES_IFCA%26sites%3DT2_FI_HIP%26sites%3DT2_FI_HIP_Test%26sites%3DT2_FR_CCIN2P3%26sites%3DT2_FR_GRIF_IRFU%26sites%3DT2_FR_GRIF_LLR%26sites%3DT2_FR_IPHC%26sites%3DT2_GR_Ioannina%26sites%3DT2_HU_Budapest%26sites%3DT2_IN_TIFR%26sites%3DT2_IT_Bari%26sites%3DT2_IT_Legnaro%26sites%3DT2_IT_LegnaroTest%26sites%3DT2_IT_Pisa%26sites%3DT2_IT_Rome%26sites%3DT2_KR_KNU%26sites%3DT2_MY_UPM_BIRUNI%26sites%3DT2_PK_NCP%26sites%3DT2_PL_Swierk%26sites%3DT2_PL_Warsaw%26sites%3DT2_PT_NCG_Lisbon%26sites%3DT2_RU_IHEP%26sites%3DT2_RU_INR%26sites%3DT2_RU_ITEP%26sites%3DT2_RU_JINR%26sites%3DT2_RU_PNPI%26sites%3DT2_RU_RRC_KI%26sites%3DT2_RU_SINP%26sites%3DT2_TH_CUNSTDA%26sites%3DT2_TR_METU%26sites%3DT2_UA_KIPT%26sites%3DT2_UK_London_Brunel%26sites%3DT2_UK_London_BrunelTest%26sites%3DT2_UK_London_IC%26sites%3DT2_UK_SGrid_Bristol%26sites%3DT2_UK_SGrid_RALPP%26sites%3DT2_US_Caltech%26sites%3DT2_US_Florida%26sites%3DT2_US_MIT%26sites%3DT2_US_Nebraska%26sites%3DT2_US_Purdue%26sites%3DT2_US_UCSD%26sites%3DT2_US_Vanderbilt%26sites%3DT2_US_Wisconsin%26sitesSort%3D2%26start%3D2015-07-01%26end%3D2015-10-01%26timeRange%3Ddaily%26granularity%3DMonthly%26generic%3D0%26sortBy%3D0%26series%3DAll%26type%3Dewa&amp;sa=D&amp;ust=1452568253788000&amp;usg=AFQjCNEopUAoLwHiFOZVMTbtNPP4CijZAQ">44%</a></span><span>&nbsp;</span><span>of all computing time by Tier-2 sites in CMS (goal is &gt;25%), being 7 of the 8 top most-used Tier-2 sites in all of global CMS.</span></p><p class="c0"><span>Figure 2: Wall clock time consumption of CMS workflows at the U.S. CMS Tier-2 sites by month.</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 476.00px;"><img alt="" src="images/image01.jpg" style="width: 624.00px; height: 476.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0 c3 c15"><span></span></p><p class="c0 c16"><span>Fourteen</span><span>&nbsp;Tier-3 sites required assistance from the Tier-3 support team this past quarter. &nbsp;These support activities include helping sites complete the transition from OSG 3.1 to 3.2, including a critical security patch for GUMS that could only be applied to sites that have already upgraded. In addition, the site support team &nbsp;continues to assist several sites in rebuilding their site in preparation for Run 2. &nbsp;In particular, there is an ongoing effort to implement a modern cluster configuration and provisioning system at the University of Maryland, as well as new efforts to rebuild clusters at Rice and FSU. &nbsp;Efforts continue to refresh documentation for site configuration and administration.</span></p><p class="c0 c10"><span>Progress on CMS Connect has focused on connecting the CMS Connect infrastructure to CMS monitoring, which has required significant software development. &nbsp;Documentation is nearly complete and beta testing should begin during the next quarter.</span></p><h1 class="c0 c10 c11"><a id="h.g51d5on8btoy" name="h.g51d5on8btoy"></a><span class="c9">Operations</span></h1><p class="c0 c3 c18"><span></span></p><p class="c0 c12"><span>In FY15 Q4, the Tier-0 was operating in data-taking mode to process data from global data taking. &nbsp;The prompt processing of the freshly recorded data was successful and proceeded without any remarkable problems. &nbsp;Smaller issues and newly appearing software were quickly resolved and adapted easily enough that one could call it &ldquo;operations as usual.&rdquo; &nbsp;We are preparing to change our present co-team leader for the Tier-0 operations (Dirk Hufnagel). He is a very valuable resource as he is also the core developer for the Tier-0 software we are now entering an operations-dominated period.</span></p><p class="c0 c3 c12"><span></span></p><p class="c0 c12"><span>The activities in Monte Carlo production and Monte Carlo and data reprocessing have been rather limited and it was easy to keep up with the incoming requests. The streamlining of the production and processing activities has continued and the operations team was very well prepared to deal with the campaigns which started in the beginning of October. In particular, the integration of the dynamic data management tool for the space occupied by production data samples will be very valuable to reduce the worry about overstepping quotas. In the 4th quarter of FY2015 we have completed 2.44B DIGI-RECO events, 3.38B GEN-SIM events and redone 50M MINIAOD. The last number is expected to increase dramatically in the next quarter as we are have just started the re-reconstruction campaign. During this quarter we have not made significant progress to run production requests on the opportunistic HLT resource as data taking has been the priority. We hope to pick up this topic in the next quarter.</span></p><p class="c0 c3 c12"><span></span></p><p class="c0 c12"><span>In the area of data transfers and data management substantial progress has been made. We have continued the integration of AAA operations and while there are still issues reported regularly the operations team is getting more comfortable with solving problems. The Dynamic Data Management has finally been deployed to carry out automatic deletions in the production data space. The strategy does not require a last copy but instead protects data from deletion by a simple locking mechanism. Any data (dataset or block level) that is in use by production at a given site has to be explicitly locked at the specific site. Thus any production activity that requires data will have to set its locks and release them once done. Many of those locks are extracted automatically from the production tools while others are entered explicitly by existing tools or by hand. The seamless integration of the dynamic data management into all production activities is expected to continue for a while before it can be considered complete. In the next quarter we expect to review the dynamic data management policies and continue development towards further optimizing space usage. Tape pledges at the Tier-1 centers have been reviewed and we are continuing our deletion campaigns to free up space on the existing tapes. The dynamic data management tools are a good candidate to to help reduce the effort used on the deletion campaigns.</span></p><h1 class="c0 c10 c11"><a id="h.wor1wud3brhr" name="h.wor1wud3brhr"></a><span class="c9">Computing Infrastructure and Services</span></h1><p class="c0 c3"><span></span></p><p class="c0"><span>This was the first quarter of Run 2 data taking. The work within U.S. CMS Computing Infrastructure and Services centered around supporting the data taking Run 2. We also continue to lay the groundwork for future improvements to come during and after Run 2. All projects have made progress on modernizing their Python code.</span></p><p class="c0 c3"><span></span></p><p class="c0"><span>During the quarter, work on the WMAgent concentrated on continued small improvements for Run 2 and the addition of new workflow types and features to support running on Amazon Web Services (AWS), including a new chained workflow type. WMAgent completed a campaign to modernize its Python code and restored automated testing of proposed changes in continuous integration. A gradual transition to Request Manager v2 continues and will be complete by FY16Q2.</span></p><p class="c0 c3"><span></span></p><p class="c0"><span>With development effectively finished for the Tier-0, the aim for FY16Q1 and beyond is to reliably operate the system during Run 2 data taking. During Q4, the Tier-0 began to produce the MINIAOD data tier. The Tier-0 was also updated to support automatic data management.</span></p><p class="c0 c3"><span></span></p><p class="c0"><span>Development responsibilities for CRAB3, begun by the U.S., have been almost completely shifted to international CMS. CRAB3 usage continues to show strong growth in at the expense of CRAB2 usage.</span></p><p class="c0 c3"><span></span></p><p class="c0"><span>DAS and DBS, the CMS metadata services, served larger and larger numbers of requests as the run began. A couple of changes enable this larger load. On the DAS side, horizontal scaling to additional servers has been implemented. DBS struggled with memory consumption issues that are being solved with Python generators. This will be moved into production in FY16Q1. </span></p><p class="c0 c3"><span></span></p><p class="c0"><span>There was one major GlideinWMS release during the quarter and two patch releases. The major release provides an important improvement for CMS: the ability to schedule an additional high-IO job in a multicore pilot. This is crucial for the Tier-0 to avoid scheduling many high-IO jobs on a single physical machine or leaving resources unallocated. This will be put into production in FY16Q1. In the future, GlideinWMS will improve the monitoring related to completed multicore glideins. &nbsp;Coupled with the AWS pilot project, the GlideinWMS team will add native configuration support for EC2 spot pricing and availability zones in the glidein factory.</span></p><p class="c0 c3"><span></span></p><p class="c0"><span>Efforts continue to increase the operational robustness of the &ldquo;Any Data, Anytime, Anywhere&rdquo; infrastructure. &nbsp;A number of issues in the stability of the regional redirectors were identified and fixed; along the way, many sites were pushed to upgrade to newer versions of Xrootd, which had a number of improvements. &nbsp;Further improvements to monitoring and testing are being considered, and the transitional federation for less-performant sites will be fully populated in the coming quarter.</span></p><p class="c0 c3"><span></span></p><p class="c0"><span>We are continuing to make progress on cloud and opportunistic resource usage. We completed our Gordon allocation, using 1.8M core hours on Gordon, roughly equivalent to 4M core hours at CMS T2 centers. This allocation was used for GEN-SIM as well as DIGI-RECO. For the latter, the pileup samples were read via XRootd from UCSD-T2, and the GEN-SIM input for DIGI-RECO were read via Xrootd from FNAL. Output was staged out directly to FNAL. Merging was run at FNAL, </span><span class="c17">i.e.</span><span>&nbsp;contrary to the previous use of Gordon in 2013, no significant disk space at Gordon was used, simplifying operations on Gordon significantly. </span></p><p class="c0 c3"><span class="c13"></span></p><p class="c0"><span>For cloud we rely on the HEPCloud project at FNAL to execute our AWS project. For our future use of NERSC and Comet, we are relying on OSG to work through the issues of using these resources. In both cases we collaborate with FNAL and OSG as needed to make progress. The goal in both cases is to establish our capability to elastically grow resources to meet deadlines.</span></p><p class="c0 c3"><span></span></p><h1 class="c0 c10 c11"><a id="h.iqzf6bds5fwv" name="h.iqzf6bds5fwv"></a><span class="c9">Software and Support</span></h1><p class="c0 c3"><span></span></p><p class="c0"><span>The U.S. CMS Software and Support group continues to contribute to the production of improved software releases to support the development of the major fronts of CMS. The CMSSW_7_4_X series is being maintained as the main production release for operating the HLT trigger and prompt reconstruction for the 2015 run. &nbsp;The introduction of the multi-threaded reconstruction has resulted in large memory savings and reduced processing latency enabling the handling of the large Run 2 trigger rates. &nbsp;As part of the commissioning and deployment of the reconstruction application, it was discovered that the special configuration used in the Tier-0, which requires many output modules and just-in-time compilation within ROOT, triggered larger concurrency inefficiencies compared to the testing configurations that had been used during the development of the threaded application. &nbsp;These problems were fixed in the development release series CMSSW_7_6_X, which will be used for the end-of-year reprocessing. &nbsp;Maintenance work was also done on the 7_4 release to allow it to be used in the HLT, which is currently running in single threaded mode. Due to a lack of sufficient memory per core it cannot sustain the required trigger rate during the last two weeks of data taking without moving to multi-threaded processing. &nbsp;In Figure 3, the point circled in black marks the current limit of the single-threaded HLT application, and the green circle marks the rate that the multi-threaded application allows. This welcomed capability comes just in time to maximize physics data taking efficiency for CMS.</span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 465.33px;"><img alt="MultiThreadHLT.png" src="images/image00.png" style="width: 624.00px; height: 465.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0 c3"><span></span></p><p class="c0"><span>Figure 3: Event throughput rates as a function of the number of threads for single- and multi-threaded applications.</span></p><p class="c0 c3"><span></span></p><p class="c0"><span>Meanwhile the 7_5_X release series is being prepared to operate during the heavy-ion run. &nbsp;In this release the GEN-SIM application has been validated to run in multi-threaded mode.</span></p><p class="c0 c3"><span></span></p></body></html>